{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "from mpl_toolkits.mplot3d import Axes3D  \n",
    "from scipy.stats import norm \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function 1 takes as input a csv file and calculates the mean spectral-temporal signature \n",
    "# for each available label in the given column. \n",
    "# @param[in] inCsvfile : a csv file exported from PlotToSat or a merged csv file\n",
    "# @param[in] col       : name of columns that medians will be calculated\n",
    "# @param[in] outCsvfile: name of file to be exported\n",
    "def getMeanSpectralTemporalSignatures(inCsvfile,col,outCsvfile):\n",
    "    csvDF = pd.read_csv(inCsvfile,low_memory=False) \n",
    "    labels = list(csvDF.columns)\n",
    "    if (col not in labels):\n",
    "        raise Exception(\"ERROR: \", col, \" not included in \", inCsvfile)\n",
    "    newLabels = [col] \n",
    "    l = 0\n",
    "    while (l<len(labels)):\n",
    "        if ((labels[l][0].isdigit() and labels[l][1]==\"_\") or \n",
    "            (labels[l][0].isdigit() and labels[l][1].isdigit() and labels[l][2]==\"_\")):\n",
    "            newLabels.append(labels[l])\n",
    "        l=l+1\n",
    "    newLabelsS1 = [col, '0_VHAsc','1_VHAsc','2_VHAsc','3_VHAsc', '4_VHAsc', '5_VHAsc','6_VHAsc', '7_VHAsc', '8_VHAsc', '9_VHAsc', '10_VHAsc','11_VHAsc', '0_VHDes','1_VHDes','2_VHDes','3_VHDes', '4_VHDes', '5_VHDes','6_VHDes', '7_VHDes', '8_VHDes', '9_VHDes', '10_VHDes','11_VHDes', '0_VVAsc','1_VVAsc','2_VVAsc','3_VVAsc', '4_VVAsc', '5_VVAsc','6_VVAsc', '7_VVAsc', '8_VVAsc', '9_VVAsc', '10_VVAsc','11_VVAsc', '0_VVDes','1_VVDes','2_VVDes','3_VVDes', '4_VVDes', '5_VVDes','6_VVDes', '7_VVDes', '8_VVDes', '9_VVDes', '10_VVDes','11_VVDes']\n",
    "    newLabelsS2 = [col, '0_B1',  '0_B2', '0_B3', '0_B4', '0_B5', '0_B6', '0_B7', '0_B8', '0_B8A', '0_B9', '0_B11', '0_B12', '1_B1',  '1_B2', '1_B3', '1_B4', '1_B5', '1_B6', '1_B7', '1_B8', '1_B8A', '1_B9','1_B11', '1_B12', '2_B1',  '2_B2', '2_B3', '2_B4', '2_B5', '2_B6', '2_B7', '2_B8', '2_B8A', '2_B9', '2_B11', '2_B12', '3_B1', '3_B2', '3_B3', '3_B4', '3_B5', '3_B6', '3_B7', '3_B8', '3_B8A', '3_B9', '3_B11', '3_B12',  '4_B1', '4_B2', '4_B3', '4_B4', '4_B5', '4_B6', '4_B7', '4_B8', '4_B8A', '4_B9',  '4_B11', '4_B12', '5_B1',  '5_B2', '5_B3', '5_B4', '5_B5', '5_B6', '5_B7', '5_B8', '5_B8A', '5_B9', '5_B11', '5_B12', '6_B1', '6_B2', '6_B3', '6_B4', '6_B5', '6_B6', '6_B7', '6_B8', '6_B8A', '6_B9', '6_B11', '6_B12',  '7_B1',  '7_B2', '7_B3', '7_B4', '7_B5', '7_B6', '7_B7', '7_B8', '7_B8A', '7_B9', '7_B11', '7_B12', '8_B1','8_B2', '8_B3', '8_B4', '8_B5', '8_B6', '8_B7', '8_B8', '8_B8A', '8_B9',  '8_B11', '8_B12',  '9_B1', '9_B2', '9_B3', '9_B4', '9_B5', '9_B6', '9_B7', '9_B8', '9_B8A', '9_B9', '9_B11', '9_B12',  '10_B1', '10_B2', '10_B3', '10_B4', '10_B5', '10_B6', '10_B7', '10_B8', '10_B8A', '10_B9','10_B11', '10_B12',  '11_B1',  '11_B2', '11_B3', '11_B4', '11_B5', '11_B6', '11_B7', '11_B8', '11_B8A', '11_B9', '11_B11', '11_B12']\n",
    "    print(newLabelsS1)\n",
    "    print(newLabelsS2)\n",
    "    \n",
    "    csvDFS1 = csvDF.loc[:,newLabelsS1]\n",
    "    csvDFS1=csvDFS1.groupby(col).mean()\n",
    "    csvDFS1.to_csv(outCsvfile+\"S1.csv\")\n",
    "    \n",
    "    csvDFS2 = csvDF.loc[:,newLabelsS2]\n",
    "    csvDFS2=csvDFS2.groupby(col).mean()\n",
    "    csvDFS2.to_csv(outCsvfile+\"S2.csv\")\n",
    "    \n",
    "    print(\"File exported in \", outCsvfile+\"S1.csv and \", outCsvfile+\"S2.csv\")  \n",
    "    \n",
    "# function 2 takes as input the output of function 1 and creates spectral-temporal signatures graphs for S2 and temporal signatures for S1   \n",
    "def createSpectralTemporalGraphs(inCsvFile,outFilestart):\n",
    "    inCsvFileS1 = inCsvFile+\"S1.csv\"\n",
    "    csvDFS1 = pd.read_csv(inCsvFileS1)\n",
    "    labels = list(csvDFS1.columns)\n",
    "    for index, row in csvDFS1.iterrows():\n",
    "        row1 = row\n",
    "        tmplist = np.array(row1)\n",
    "        rowlist = []\n",
    "        for item in tmplist:\n",
    "            rowlist = rowlist + [item]\n",
    "        modulo = (len(rowlist)-1)%12\n",
    "        if (modulo!=0 and len(rowlist<=0)):\n",
    "            raise Exception(\"this is not a 12 months spectral temporal signature\")      \n",
    "        outImg = outFilestart+\"_\"+rowlist[0]+\"_S1.jpg\"\n",
    "        data =  [rowlist[1:13],rowlist[13:25],rowlist[25:37],rowlist[37:49]]\n",
    "        data = np.array(data)\n",
    "        months = [0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "        plt.figure(figsize=(10, 9)) \n",
    "        plt.plot(months,data[0],label = \"VV Ascending\", color=\"#F5793A\") # magenta\n",
    "        plt.plot(months,data[1],label = \"VV Descending\", color=\"#A95AA1\") # blue\n",
    "        plt.plot(months,data[2],label = \"VH Ascending\", color=\"#85C0F9\") # yellow\n",
    "        plt.plot(months,data[3],label = \"VH Descending\", color=\"#0F2080\") # green\n",
    "\n",
    "        plt.xlabel('Month', fontsize=23)  # Adjust fontsize as needed\n",
    "        plt.ylabel('Mean backscattering coefficient', fontsize=24) \n",
    "        plt.xticks(months, [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"], fontsize=16)  # Adjust fontsize as needed\n",
    "        plt.xticks(fontsize = 21)\n",
    "        plt.yticks(fontsize = 21)\n",
    "        plt.ylim(-18, -8)\n",
    "        plt.legend(fontsize=24)\n",
    "        plt.savefig(outImg, dpi=100)\n",
    "        plt.clf()\n",
    "    \n",
    "        \n",
    "    inCSVFileS2 = inCsvFile+\"S2.csv\"   \n",
    "    csvDFS2 = pd.read_csv(inCSVFileS2)\n",
    " \n",
    "    labels = list(csvDFS2.columns)\n",
    "    for index, row in csvDFS2.iterrows():\n",
    "        row1 = row\n",
    "        tmplist = np.array(row1)\n",
    "        rowlist = []\n",
    "        for item in tmplist:\n",
    "            rowlist = rowlist + [item]\n",
    "        modulo = (len(rowlist)-1)%12\n",
    "        if (modulo!=0 and len(rowlist<=0)):\n",
    "            raise Exception(\"this is not a 12 months spectral temporal signature\")\n",
    "        outImg = outFilestart+\"_\"+rowlist[0]+\"_S2.jpg\"\n",
    "        print(outImg)\n",
    "        data =  [rowlist[      1:12   +1], #'0_B1',  '0_B2', '0_B3', '0_B4', '0_B5', '0_B6', '0_B7', '0_B8', '0_B8A', '0_B9', '0_B11', '0_B12', \n",
    "                 rowlist[12   +1:12* 2+1], #'1_B1',  '1_B2', '1_B3', '1_B4', '1_B5', '1_B6', '1_B7', '1_B8', '1_B8A', '1_B9','1_B11', '1_B12', \n",
    "                 rowlist[12* 2+1:12* 3+1], #'2_B1',  '2_B2', '2_B3', '2_B4', '2_B5', '2_B6', '2_B7', '2_B8', '2_B8A', '2_B9', '2_B11', '2_B12', \n",
    "                 rowlist[12* 3+1:12* 4+1], #'3_B1', '3_B2', '3_B3', '3_B4', '3_B5', '3_B6', '3_B7', '3_B8', '3_B8A', '3_B9', '3_B11', '3_B12',  \n",
    "                 rowlist[12* 4+1:12* 5+1], #'4_B1', '4_B2', '4_B3', '4_B4', '4_B5', '4_B6', '4_B7', '4_B8', '4_B8A', '4_B9',  '4_B11', '4_B12', \n",
    "                 rowlist[12* 5+1:12* 6+1], #'5_B1',  '5_B2', '5_B3', '5_B4', '5_B5', '5_B6', '5_B7', '5_B8', '5_B8A', '5_B9', '5_B11', '5_B12', \n",
    "                 rowlist[12* 6+1:12* 7+1], #'6_B1', '6_B2', '6_B3', '6_B4', '6_B5', '6_B6', '6_B7', '6_B8', '6_B8A', '6_B9', '6_B11', '6_B12',  \n",
    "                 rowlist[12* 7+1:12* 8+1], #'7_B1',  '7_B2', '7_B3', '7_B4', '7_B5', '7_B6', '7_B7', '7_B8', '7_B8A', '7_B9', '7_B11', '7_B12', \n",
    "                 rowlist[12* 8+1:12* 9+1], #'8_B1','8_B2', '8_B3', '8_B4', '8_B5', '8_B6', '8_B7', '8_B8', '8_B8A', '8_B9',  '8_B11', '8_B12',  \n",
    "                 rowlist[12* 9+1:12*10+1], #'9_B1', '9_B2', '9_B3', '9_B4', '9_B5', '9_B6', '9_B7', '9_B8', '9_B8A', '9_B9', '9_B11', '9_B12', \n",
    "                 rowlist[12*10+1:12*11+1], # '10_B1', '10_B2', '10_B3', '10_B4', '10_B5', '10_B6', '10_B7', '10_B8', '10_B8A', '10_B9','10_B11', \n",
    "                 rowlist[12*11+1:12*12+1]] #'10_B12',  '11_B1',  '11_B2', '11_B3', '11_B4', '11_B5', '11_B6', '11_B7', '11_B8', '11_B8A', '11_B9', '11_B11', '11_B12'\n",
    "        data = np.array(data)\n",
    "        data = np.transpose(data)     \n",
    "        fig, (ax, bx) = plt.subplots(nrows=1, ncols=2, num=0, figsize=(16, 8),\n",
    "                             subplot_kw={'projection': '3d'})\n",
    "        for i in range(data.shape[1]):\n",
    "            ax.plot3D(np.repeat(i, data.shape[0]), np.arange(data.shape[0]),data[:, i])\n",
    "        gridX, gridY = np.mgrid[1:data.shape[0]:data.shape[0] * 1j,\n",
    "                                1:data.shape[1]:data.shape[1] * 1j]\n",
    "        ax.set_xlabel('Band')\n",
    "        ax.set_ylabel('Month')\n",
    "        ax.set_zlabel('Mean Spectral Value')\n",
    "        bx.set_xlabel('Band')\n",
    "        bx.set_ylabel('Month')\n",
    "        bx.set_xticklabels([\"B1\",\"B3\",\"B5\",\"B7\",\"B8A\",\"B11\", \"\"])\n",
    "        ax.set_xticklabels([\"B1\",\"B1\",\"B3\",\"B5\",\"B7\",\"B8A\",\"B11\", \"\"])\n",
    "        bx.set_yticklabels([\"Jan\",  \"Mar\",  \"May\",\"Jul\",  \"Sep\",  \"Nov\"])\n",
    "        ax.set_yticklabels([\"Jan\",\"Jan\", \"Mar\", \"May\", \"Jul\", \"Sep\", \"Nov\"])\n",
    "        ax.set_zlim(0, 3500)\n",
    "        bx.set_zlim(0, 3500)\n",
    "        pSurf = bx.plot_surface(gridY, gridX, data, cmap='viridis')\n",
    "        pSurf = bx.plot_surface(gridY, gridX, data, cmap='viridis', vmin=0, vmax=3500)\n",
    "        fig.colorbar(pSurf)\n",
    "        plt.savefig(outImg)\n",
    "        plt.clf()\n",
    "    print(\"hello\")\n",
    "\n",
    "\n",
    "def createMultiTemporalGraphsFromOneFile(inCsvFile, outFilestart):\n",
    "    inCsvFileS1 = inCsvFile\n",
    "    csvDFS1 = pd.read_csv(inCsvFileS1)\n",
    "    labels = list(csvDFS1.columns)\n",
    "\n",
    "    # Create subplots for all classes\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "\n",
    "    class_names = [\"VV Ascending\", \"VV Descending\", \"VH Ascending\", \"VH Descending\"]\n",
    "\n",
    "    for i in range(3):  # Assuming there are three classes\n",
    "        row = csvDFS1.iloc[i]  # Get the row corresponding to the class\n",
    "        rowlist = row.tolist()\n",
    "        data = [rowlist[1:13], rowlist[13:25], rowlist[25:37], rowlist[37:49]]\n",
    "        data = np.array(data)\n",
    "\n",
    "        # Plot each class on its corresponding subplot\n",
    "        for j in range(4):\n",
    "            months = range(1, 13)\n",
    "            axes[i].plot(months, data[j], label=class_names[j])\n",
    "\n",
    "        axes[i].set_xlabel('Month')\n",
    "        axes[i].set_ylabel('Mean backscattering coefficient')\n",
    "        axes[i].set_xticks(months)\n",
    "        axes[i].set_xticklabels([\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"])\n",
    "        axes[i].legend()\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save or show the plot\n",
    "    plt.savefig(outFilestart, dpi=100)\n",
    "    plt.close(fig)\n",
    "    plt.clf()\n",
    "    print (\"Image saved in \", outFilestart)    \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def createMultiTemporalGraphsFromMultipleFiles(inCsvFiles, outFilestart):\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 15))\n",
    "\n",
    "    class_names = [\"VV Ascending\", \"VV Descending\", \"VH Ascending\", \"VH Descending\"]\n",
    "    column_labels = [\"Months in 2018\", \"Months in 2019\", \"Months in 2020\"]\n",
    "    y_labels = [\"Broad-leaved deciduous\\nMean backscattering coefficient\", \"Broad-leaved evergreen\\nMean backscattering coefficient\", \"Needle-leaved evergreen\\nMean backscattering coefficient\"]\n",
    "\n",
    "    for i in range(3):  # For each row (class)\n",
    "        for j in range(3):  # For each column (file)\n",
    "            inCsvFile = inCsvFiles[j]\n",
    "            csvDFS1 = pd.read_csv(inCsvFile)\n",
    "            row = csvDFS1.iloc[i]  # Get the row corresponding to the class\n",
    "            rowlist = row.tolist()\n",
    "            data = [rowlist[1:13], rowlist[13:25], rowlist[25:37], rowlist[37:49]]\n",
    "            data = np.array(data)\n",
    "\n",
    "            # Plot each class on its corresponding subplot\n",
    "            for k in range(4):\n",
    "                months = range(1, 13)\n",
    "                axes[i, j].plot(months, data[k], label=class_names[k], linewidth=2)\n",
    "\n",
    "            # Set axis labels font size\n",
    "            if i == 2:\n",
    "                axes[i, j].set_xlabel(column_labels[j], fontsize=16)\n",
    "            if j == 0:\n",
    "                axes[i, j].set_ylabel(y_labels[i], fontsize=16)\n",
    "\n",
    "            # Set tick labels font size\n",
    "            axes[i, j].tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "            # Show ticks and labels only on the lower x-axis and the left y-axis\n",
    "            if i == 2:\n",
    "                axes[i, j].set_xticks(months)\n",
    "                axes[i, j].set_xticklabels([\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"])\n",
    "            else:\n",
    "                axes[i, j].set_xticks([])\n",
    "\n",
    "            if j == 0:\n",
    "                axes[i, j].set_yticks(np.arange(-18.5, -8.5, 2))\n",
    "            else:\n",
    "                axes[i, j].set_yticks([])\n",
    "\n",
    "            # Set legend in the middle of the graph\n",
    "            if i == 2 and j == 2:\n",
    "                axes[i, j].legend(loc='center', fontsize=14, bbox_to_anchor=(0.5, 0.5))\n",
    "\n",
    "    # Set consistent y-axis limits across all subplots\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            axes[i, j].set_ylim(-18.5, -8.5)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save or show the plot\n",
    "    plt.savefig(outFilestart, dpi=120)\n",
    "    plt.close(fig)\n",
    "    plt.clf()\n",
    "    print (\"Image saved in \", outFilestart)   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def createMultiSpectralTemporalGraphsLines(inCsvFiles, outFilestart):\n",
    "    if len(inCsvFiles) != 3:\n",
    "        raise ValueError(\"Input must contain 3 CSV files\")\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(16, 16), subplot_kw={'projection': '3d'})\n",
    "\n",
    "    for idx, inCsvFile in enumerate(inCsvFiles):\n",
    "        csvDFS = pd.read_csv(inCsvFile)\n",
    "        labels = list(csvDFS.columns)\n",
    "\n",
    "        for index, row in csvDFS.iterrows():\n",
    "            row1 = row\n",
    "            tmplist = np.array(row1)\n",
    "            rowlist = []\n",
    "            for item in tmplist:\n",
    "                rowlist = rowlist + [item]\n",
    "            modulo = (len(rowlist) - 1) % 12\n",
    "            if modulo != 0 or len(rowlist) <= 0:\n",
    "                raise Exception(\"This is not a 12 months spectral temporal signature\")\n",
    "            outImg = outFilestart + \"_{}_S2.jpg\".format(rowlist[0])\n",
    "            print(outImg)\n",
    "            data = [rowlist[(i * 12) + 1:((i + 1) * 12) + 1] for i in range(12)]  # Splitting into 12-month chunks\n",
    "            data = np.array(data)\n",
    "            data = np.transpose(data)\n",
    "            for i in range(data.shape[1]):\n",
    "                axes[index, idx].plot3D(np.repeat(i, data.shape[0]), np.arange(data.shape[0]), data[:, i])\n",
    "\n",
    "            axes[index, idx].set_xlabel('Band')\n",
    "            axes[index, idx].set_ylabel('Month')\n",
    "            axes[index, idx].set_zlabel('Mean Spectral Value')\n",
    "            axes[index, idx].set_xticklabels([\"B1\", \"B3\", \"B5\", \"B7\", \"B8A\", \"B11\", \"\"])\n",
    "            axes[index, idx].set_yticklabels([\"Jan\", \"Mar\", \"May\", \"Jul\", \"Sep\", \"Nov\"])\n",
    "            axes[index, idx].set_zlim(0, 3500)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outFilestart)\n",
    "    plt.clf()\n",
    "    print(\"file saved in \", outFilestart)\n",
    "\n",
    "\n",
    "def createMultiSpectralTemporalGraphsSurface(inCsvFiles, outFilestart):\n",
    "    if len(inCsvFiles) != 3:\n",
    "        raise ValueError(\"Input must contain 3 CSV files\")\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 18))\n",
    "\n",
    "    for idx, inCsvFile in enumerate(inCsvFiles):\n",
    "        csvDFS = pd.read_csv(inCsvFile)\n",
    "        labels = list(csvDFS.columns)\n",
    "\n",
    "        for index, row in csvDFS.iterrows():\n",
    "            row1 = row\n",
    "            tmplist = np.array(row1)\n",
    "            rowlist = []\n",
    "            for item in tmplist:\n",
    "                rowlist = rowlist + [item]\n",
    "            modulo = (len(rowlist) - 1) % 12\n",
    "            if modulo != 0 or len(rowlist) <= 0:\n",
    "                raise Exception(\"This is not a 12 months spectral temporal signature\")\n",
    "            outImg = outFilestart + \"_{}_S2.jpg\".format(rowlist[0])\n",
    "            print(outImg)\n",
    "            data = [rowlist[(i * 12) + 1:((i + 1) * 12) + 1] for i in range(12)]  # Splitting into 12-month chunks\n",
    "            data = np.array(data)\n",
    "            X, Y = np.meshgrid(range(data.shape[0]), range(data.shape[1]))  # Transpose X and Y\n",
    "            Z = data.astype(float)\n",
    "            ax = fig.add_subplot(3, 4, index * 4 + idx + 1, projection='3d')\n",
    "            surf = ax.plot_surface(Y, X, Z, cmap='viridis', edgecolor='none', vmin=0, vmax=3500)\n",
    "            ax.set_xlabel('Band')\n",
    "            ax.set_ylabel('Month')\n",
    "            ax.set_zlabel('Mean Spectral Value')\n",
    "            ax.set_yticklabels([\"\", \"Jan\", \"Mar\", \"May\", \"Jul\", \"Sep\", \"Nov\"])\n",
    "            ax.set_xticklabels([\"\", \"B1\", \"B3\", \"B5\", \"B7\", \"B8A\", \"B12\"])  \n",
    "            ax.set_zlim(0, 3500)\n",
    "            ax.yaxis.set_rotate_label(True)  # Enable automatic rotation of the y-axis label\n",
    "            ax.xaxis.set_rotate_label(True)  # Enable automatic rotation of the x-axis label\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outFilestart)\n",
    "    plt.clf()\n",
    "    print(\"file saved in \", outFilestart)\n",
    "\n",
    "\n",
    "## function 2.51 takes as input the output of function 1\n",
    "## takes as input 9 files and creates a 3x3 grid with multi-line graphs\n",
    "# @parma[in] inCsvFiles: the list of the csv files to be imported\n",
    "# @param[in] outFile: the name and directory of the image to be exported\n",
    "def createS1TemporalMultiGraphs(row_labels, inCsvFiles, outFilestart):\n",
    "    if len(row_labels) != 3 or len(inCsvFiles) != 3:\n",
    "        raise ValueError(\"Input must contain 3 row labels and 3 CSV files\")\n",
    "\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(18, 18))\n",
    "\n",
    "    for i, (row_label, inCsvFile) in enumerate(zip(row_labels, inCsvFiles)):\n",
    "        inCsvFileS1 = inCsvFile \n",
    "        csvDFS1 = pd.read_csv(inCsvFileS1)\n",
    "        labels = list(csvDFS1.columns)\n",
    "\n",
    "        for label in row_label:\n",
    "            for index, row in csvDFS1.iterrows():\n",
    "                if row[0] == label:\n",
    "                    print ( row[0])\n",
    "                    row1 = row\n",
    "                    tmplist = np.array(row1)\n",
    "                    rowlist = []\n",
    "                    for item in tmplist:\n",
    "                        rowlist = rowlist + [item]\n",
    "                    modulo = (len(rowlist) - 1) % 12\n",
    "                    if (modulo != 0 and len(rowlist <= 0)):\n",
    "                        raise Exception(\"this is not a 12 months spectral temporal signature\")\n",
    "                    data = [rowlist[25:36], rowlist[37:48], rowlist[1:12], rowlist[13:24]]\n",
    "                    data = np.array(data)\n",
    "                    months = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "\n",
    "                    ax = axs[i // 3, i % 3]\n",
    "                    ax.plot(months, data[0], label=\"VV Ascending\", color=\"#D81B60\")  # magenta\n",
    "                    ax.plot(months, data[1], label=\"VV Descending\", color=\"#1E88E5\")  # blue\n",
    "                    ax.plot(months, data[2], label=\"VH Ascending\", color=\"#FFC107\")  # yellow\n",
    "                    ax.plot(months, data[3], label=\"VH Descending\", color=\"#004D40\")  # green\n",
    "                    ax.set_xlabel('Month', fontsize=12)\n",
    "                    ax.set_ylabel('Mean backscattering coefficient', fontsize=12)\n",
    "                    ax.set_xticks(months)\n",
    "                    ax.set_xticklabels(\n",
    "                        [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"],\n",
    "                        fontsize=10)\n",
    "                    ax.set_yticks(fontsize=10)\n",
    "                    ax.set_ylim(-18, -9)\n",
    "                    ax.legend(fontsize=12)\n",
    "                    ax.set_title(inCsvFile, fontsize=14)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outFilestart + \"_spectral_temporal_graphs.jpg\", dpi=100)\n",
    "    plt.show()\n",
    "\n",
    "# function 3 takes as input the outpus of function 1 and produces the annual mean for each band \n",
    "def getMeanPerBandfromMeans(inCsvFile,col,outCsvfile):\n",
    "    inCsvFileS1 = inCsvFile+\"S1.csv\"\n",
    "    inCsvFileS2 = inCsvFile+\"S2.csv\"\n",
    "\n",
    "    csvDFS2 = pd.read_csv(inCsvFileS2)\n",
    "    # '0_B1',  '0_B2', '0_B3', '0_B4', '0_B5', '0_B6', '0_B7', '0_B8', '0_B8A', '0_B9', '0_B11', '0_B12', \n",
    "    dfS2  = csvDFS2[[col]]\n",
    "    dfS2 ['B1' ] = csvDFS2 [['0_B1', '1_B1', '2_B1', '3_B1', '4_B1', '5_B1', '6_B1', '7_B1', '8_B1', '9_B1', '10_B1', '11_B1' ]].mean(axis=1) # '0_B1', \n",
    "    dfS2 ['B2' ] = csvDFS2 [['0_B2', '1_B2', '2_B2', '3_B2', '4_B2', '5_B2', '6_B2', '7_B2', '8_B2', '9_B2', '10_B2', '11_B2' ]].mean(axis=1) # '0_B2', \n",
    "    dfS2 ['B3' ] = csvDFS2 [['0_B3', '1_B3', '2_B3', '3_B3', '4_B3', '5_B3', '6_B3', '7_B3', '8_B3', '9_B3', '10_B3', '11_B3' ]].mean(axis=1) # '0_B3\n",
    "    dfS2 ['B4' ] = csvDFS2 [['0_B4', '1_B4', '2_B4', '3_B4', '4_B4', '5_B4', '6_B4', '7_B4', '8_B4', '9_B4', '10_B4', '11_B4' ]].mean(axis=1) # '0_B4', \n",
    "    dfS2 ['B5' ] = csvDFS2 [['0_B5', '1_B5', '2_B5', '3_B5', '4_B5', '5_B5', '6_B5', '7_B5', '8_B5', '9_B5', '10_B5', '11_B5' ]].mean(axis=1) # '0_B5',\n",
    "    dfS2 ['B6' ] = csvDFS2 [['0_B6', '1_B6', '2_B6', '3_B6', '4_B6', '5_B6', '6_B6', '7_B6', '8_B6', '9_B6', '10_B6', '11_B6' ]].mean(axis=1) # '0_B6',\n",
    "    dfS2 ['B7' ] = csvDFS2 [['0_B7', '1_B7', '2_B7', '3_B7', '4_B7', '5_B7', '6_B7', '7_B7', '8_B7', '9_B7', '10_B7', '11_B7' ]].mean(axis=1) # '0_B7',\n",
    "    dfS2 ['B8' ] = csvDFS2 [['0_B8', '1_B8', '2_B8', '3_B8', '4_B8', '5_B8', '6_B8', '7_B8', '8_B8', '9_B8', '10_B8', '11_B8' ]].mean(axis=1) # '0_B8',\n",
    "    dfS2 ['B8A'] = csvDFS2 [['0_B8A','1_B8A','2_B8A','3_B8A','4_B8A','5_B8A','6_B8A','7_B8A','8_B8A','9_B8A','10_B8A','11_B8A']].mean(axis=1) # '0_B8A',\n",
    "    dfS2 ['B9' ] = csvDFS2 [['0_B9', '1_B9', '2_B9', '3_B9', '4_B9', '5_B9', '6_B9', '7_B9', '8_B9', '9_B9', '10_B9', '11_B9' ]].mean(axis=1) # '0_B9',\n",
    "    dfS2 ['B11'] = csvDFS2 [['0_B11','1_B11','2_B11','3_B11','4_B11','5_B11','6_B11','7_B11','8_B11','9_B11','10_B11','11_B11']].mean(axis=1) # '0_B11',\n",
    "    dfS2 ['B12'] = csvDFS2 [['0_B12','1_B12','2_B12','3_B12','4_B12','5_B12','6_B12','7_B12','8_B12','9_B12','10_B12','11_B12']].mean(axis=1) # '0_B12',\n",
    "    dfS2.to_csv(outCsvfile+\"S2.csv\")\n",
    "    print (\"Means saved in \", outCsvfile+\"S2.csv\")\n",
    "\n",
    "    csvDFS1 = pd.read_csv(inCsvFileS1)\n",
    "    # '0_VHAsc' 0_VHDes 0_VVAsc 0_VVDes\n",
    "    dfS1 =  csvDFS1[[col]]\n",
    "    dfS1['VHAsc'] = csvDFS1[['0_VHAsc', '1_VHAsc', '2_VHAsc', '3_VHAsc', '4_VHAsc', '5_VHAsc', '6_VHAsc', '7_VHAsc', '8_VHAsc', '9_VHAsc', '10_VHAsc', '11_VHAsc']].mean(axis=1) # '0_VHAsc',\n",
    "    dfS1['VVAsc'] = csvDFS1[['0_VVAsc', '1_VVAsc', '2_VVAsc', '3_VVAsc', '4_VVAsc', '5_VVAsc', '6_VVAsc', '7_VVAsc', '8_VVAsc', '9_VVAsc', '10_VVAsc', '11_VVAsc']].mean(axis=1)  # '0_VVAsc',  \n",
    "    dfS1['VHDes'] = csvDFS1[['0_VHDes', '1_VHDes', '2_VHDes', '3_VHDes', '4_VHDes', '5_VHDes', '6_VHDes', '7_VHDes', '8_VHDes', '9_VHDes', '10_VHDes', '11_VHDes']].mean(axis=1)  # '0_VHDes',      \n",
    "    dfS1['VVDes'] = csvDFS1[['0_VVDes', '1_VVDes', '2_VVDes', '3_VVDes', '4_VVDes', '5_VVDes', '6_VVDes', '7_VVDes', '8_VVDes', '9_VVDes', '10_VVDes', '11_VVDes']].mean(axis=1)  # '0_VVDes',  \n",
    "    dfS1.to_csv(outCsvfile+\"S1.csv\")\n",
    "    print (\"Means saved in \", outCsvfile+\"S1.csv\")\n",
    "\n",
    "# function 4 takes as input the outpus of PlotToSat and produces the annual mean for each band \n",
    "def getMeanPerBand(inCsvFile,col,outCsvfile):\n",
    "    csvDFS = pd.read_csv(inCsvFile)\n",
    "    # '0_B1',  '0_B2', '0_B3', '0_B4', '0_B5', '0_B6', '0_B7', '0_B8', '0_B8A', '0_B9', '0_B11', '0_B12', \n",
    "    dfS2  = csvDFS[[col]]\n",
    "    dfS2 ['B1' ] = csvDFS [['0_B1', '1_B1', '2_B1', '3_B1', '4_B1', '5_B1', '6_B1', '7_B1', '8_B1', '9_B1', '10_B1', '11_B1' ]].mean(axis=1) # '0_B1', \n",
    "    dfS2 ['B2' ] = csvDFS [['0_B2', '1_B2', '2_B2', '3_B2', '4_B2', '5_B2', '6_B2', '7_B2', '8_B2', '9_B2', '10_B2', '11_B2' ]].mean(axis=1) # '0_B2', \n",
    "    dfS2 ['B3' ] = csvDFS [['0_B3', '1_B3', '2_B3', '3_B3', '4_B3', '5_B3', '6_B3', '7_B3', '8_B3', '9_B3', '10_B3', '11_B3' ]].mean(axis=1) # '0_B3\n",
    "    dfS2 ['B4' ] = csvDFS [['0_B4', '1_B4', '2_B4', '3_B4', '4_B4', '5_B4', '6_B4', '7_B4', '8_B4', '9_B4', '10_B4', '11_B4' ]].mean(axis=1) # '0_B4', \n",
    "    dfS2 ['B5' ] = csvDFS [['0_B5', '1_B5', '2_B5', '3_B5', '4_B5', '5_B5', '6_B5', '7_B5', '8_B5', '9_B5', '10_B5', '11_B5' ]].mean(axis=1) # '0_B5',\n",
    "    dfS2 ['B6' ] = csvDFS [['0_B6', '1_B6', '2_B6', '3_B6', '4_B6', '5_B6', '6_B6', '7_B6', '8_B6', '9_B6', '10_B6', '11_B6' ]].mean(axis=1) # '0_B6',\n",
    "    dfS2 ['B7' ] = csvDFS [['0_B7', '1_B7', '2_B7', '3_B7', '4_B7', '5_B7', '6_B7', '7_B7', '8_B7', '9_B7', '10_B7', '11_B7' ]].mean(axis=1) # '0_B7',\n",
    "    dfS2 ['B8' ] = csvDFS [['0_B8', '1_B8', '2_B8', '3_B8', '4_B8', '5_B8', '6_B8', '7_B8', '8_B8', '9_B8', '10_B8', '11_B8' ]].mean(axis=1) # '0_B8',\n",
    "    dfS2 ['B8A'] = csvDFS [['0_B8A','1_B8A','2_B8A','3_B8A','4_B8A','5_B8A','6_B8A','7_B8A','8_B8A','9_B8A','10_B8A','11_B8A']].mean(axis=1) # '0_B8A',\n",
    "    dfS2 ['B9' ] = csvDFS [['0_B9', '1_B9', '2_B9', '3_B9', '4_B9', '5_B9', '6_B9', '7_B9', '8_B9', '9_B9', '10_B9', '11_B9' ]].mean(axis=1) # '0_B9',\n",
    "    dfS2 ['B11'] = csvDFS [['0_B11','1_B11','2_B11','3_B11','4_B11','5_B11','6_B11','7_B11','8_B11','9_B11','10_B11','11_B11']].mean(axis=1) # '0_B11',\n",
    "    dfS2 ['B12'] = csvDFS [['0_B12','1_B12','2_B12','3_B12','4_B12','5_B12','6_B12','7_B12','8_B12','9_B12','10_B12','11_B12']].mean(axis=1) # '0_B12',\n",
    "    dfS2.to_csv(outCsvfile+\"S2.csv\")\n",
    "    print (\"Means saved in \", outCsvfile+\"S2.csv\")\n",
    "\n",
    "    # '0_VHAsc' 0_VHDes 0_VVAsc 0_VVDes\n",
    "    dfS1 =  csvDFS[[col]]\n",
    "    dfS1['VHAsc'] = csvDFS[['0_VHAsc', '1_VHAsc', '2_VHAsc', '3_VHAsc', '4_VHAsc', '5_VHAsc', '6_VHAsc', '7_VHAsc', '8_VHAsc', '9_VHAsc', '10_VHAsc', '11_VHAsc']].mean(axis=1) # '0_VHAsc',\n",
    "    dfS1['VVAsc'] = csvDFS[['0_VVAsc', '1_VVAsc', '2_VVAsc', '3_VVAsc', '4_VVAsc', '5_VVAsc', '6_VVAsc', '7_VVAsc', '8_VVAsc', '9_VVAsc', '10_VVAsc', '11_VVAsc']].mean(axis=1)  # '0_VVAsc',  \n",
    "    dfS1['VHDes'] = csvDFS[['0_VHDes', '1_VHDes', '2_VHDes', '3_VHDes', '4_VHDes', '5_VHDes', '6_VHDes', '7_VHDes', '8_VHDes', '9_VHDes', '10_VHDes', '11_VHDes']].mean(axis=1)  # '0_VHDes',      \n",
    "    dfS1['VVDes'] = csvDFS[['0_VVDes', '1_VVDes', '2_VVDes', '3_VVDes', '4_VVDes', '5_VVDes', '6_VVDes', '7_VVDes', '8_VVDes', '9_VVDes', '10_VVDes', '11_VVDes']].mean(axis=1)  # '0_VVDes',  \n",
    "    dfS1.to_csv(outCsvfile+\"S1.csv\")\n",
    "    print (\"Means saved in \", outCsvfile+\"S1.csv\")\n",
    "    \n",
    "    \n",
    "# function 5 that adds NDVI to the S2 output of function 3 or 4 \n",
    "def addNDVI(inCsvFile, outCsvFile):\n",
    "    dfS2 = pd.read_csv(inCsvFile+\"S2.csv\")\n",
    "    dfS2['NDVI'] = (dfS2['B8']-dfS2['B4'])/(dfS2['B8']+dfS2['B4'])   # NDVI = (NIR-B8 - RED-B4) / (NIR-B8 + RED-B4) \n",
    "    dfS2.to_csv(outCsvFile)\n",
    "    print (outCsvFile, \"saved\")\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "# function 6 that takes as input a csv file and exports a histogram with the distribution line\n",
    "# @param[in] col, the name of the colmun of which the histogram will be derived\n",
    "def saveHist(inCsvFile, col, outHist):\n",
    "    df = pd.read_csv(inCsvFile) \n",
    "    data = np.array(df[col].tolist())  \n",
    "    data = [i for i in data if i is not None]\n",
    "    data = [x for x in data if ~np.isnan(x)]\n",
    "    data = [i for i in data if i!='nan']\n",
    "    mu, std = norm.fit(data)  \n",
    "  \n",
    "    # Plot the histogram. \n",
    "    plt.hist(data, bins=25, density=True, alpha=0.6, color='b') \n",
    "    \n",
    "    # Plot the PDF. \n",
    "    xmin, xmax = plt.xlim() \n",
    "    x = np.linspace(xmin, xmax, 100) \n",
    "    p = norm.pdf(x, mu, std) \n",
    "    \n",
    "    plt.plot(x, p, 'k', linewidth=2) \n",
    "    title = \"Mean: {:.2f}, Std {:.2f}\".format(mu, std) \n",
    "    plt.title(title)   \n",
    "    plt.savefig(outHist)\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "def saveMultiHist(inCsvFiles, col_name, outHist, row_labels=None, col_labels=None):\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(18, 15), sharex=True, sharey=True)\n",
    "    \n",
    "    for i, csv_file in enumerate(inCsvFiles):\n",
    "        row = i // 3\n",
    "        col = i % 3\n",
    "        \n",
    "        df = pd.read_csv(csv_file)\n",
    "        data = np.array(df[col_name].dropna())\n",
    "        mu, std = norm.fit(data)  \n",
    "            \n",
    "        ax = axs[row, col]\n",
    "        counts, bins, _ = ax.hist(data, bins=25, density=False, alpha=0.6, color='b')  # Density=False to plot counts\n",
    "\n",
    "        mode_value = bins[np.argmax(counts)]  # Finding the mode value\n",
    "        \n",
    "        xmin, xmax = 0, 1.25  # Limiting x-axis from 0 to 1.25\n",
    "        ax.set_xlim(xmin, xmax)\n",
    "        \n",
    "        x = np.linspace(xmin, xmax, 100) \n",
    "        p = norm.pdf(x, mu, std) \n",
    "\n",
    "        ax.plot(x, p * len(data) * np.diff(bins)[0], 'k', linewidth=2)  # Plotting PDF scaled by total count\n",
    "        \n",
    "        title = \"Mean: {:.2f}, Std {:.2f}, Mode {:.2f}\".format(mu, std, mode_value)  # Adding mode to the title\n",
    "        ax.set_title(title, fontsize=14)\n",
    "        \n",
    "    # Add row labels\n",
    "    if row_labels:\n",
    "        for i, label in enumerate(row_labels):\n",
    "            axs[i, 0].set_ylabel(label, fontsize=14)\n",
    "    \n",
    "    # Add column labels\n",
    "    if col_labels:\n",
    "        for j, label in enumerate(col_labels):\n",
    "            axs[2, j].set_xlabel(label, fontsize=14)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjusting layout slightly to ensure labels are visible\n",
    "    plt.savefig(outHist)\n",
    "    plt.close(fig)\n",
    "\n",
    "## function 7 that takes as input a csv file and exports a csv files for each available label in a given column\n",
    "# for each available label in the given column. \n",
    "# @param[in] inCsvfile : a csv file exported from PlotToSat or a merged csv file\n",
    "# @param[in] col       : name of columns that medians will be calculated\n",
    "# @param[in] outCsvfile: name of file to be exported\n",
    "def divideDataAccordingLabels(inCsvfile,col,outCsvfolder):\n",
    "    if (os.path.exists(outCsvfolder)):\n",
    "       print(\"WARNING: Directory \", outCsvfolder, \"exist.\")\n",
    "    else:\n",
    "        os.mkdir(outCsvfolder)\n",
    "    \n",
    "    csvDF = pd.read_csv(inCsvfile,low_memory=False) \n",
    "    \n",
    "    dfs = [x.reset_index(drop=True) for _, x in csvDF.groupby(col)]\n",
    "    [x.to_csv(f\"{outCsvfolder}{x[col][0]}.csv\", index=False) for x in dfs]    \n",
    "    \n",
    " \n",
    "## function 8 for each biome get th means and the hist graphs using previous graphs and spectral-temporal graphs\n",
    "def getAll(inCsvFile,col,OutFolder):\n",
    "    if (OutFolder[-1]!=[\"/\"]):\n",
    "        OutFolder = OutFolder+\"/\"\n",
    "    \n",
    "    if (os.path.exists(OutFolder)):\n",
    "       print(\"WARNING: Directory \", OutFolder, \"exist. \", OutFolder, \"is removed!\")\n",
    "       shutil.rmtree(OutFolder)\n",
    "    os.mkdir(OutFolder)\n",
    "       \n",
    "    getMeanSpectralTemporalSignatures(inCsvFile,col,OutFolder+\"classMeans.csv\")\n",
    "    createSpectralTemporalGraphs(OutFolder+\"classMeans.csv\",OutFolder+\"classMeans\") \n",
    "    \n",
    "    getMeanPerBand(inCsvFile,col,OutFolder+\"_annualMeans.csv\")\n",
    "    addNDVI(OutFolder+\"_annualMeans.csv\", OutFolder+\"_annualMeans_NDVI.csv\")\n",
    "    divideDataAccordingLabels(OutFolder+\"_annualMeans_NDVI.csv\",col,OutFolder)\n",
    "\n",
    "    csvDFmeans = pd.read_csv(OutFolder+\"classMeans.csvS1.csv\")\n",
    "    labels = np.array(csvDFmeans[col].tolist()) # the unique labels of the column of interest\n",
    "    \n",
    "    labels = [i for i in labels if i is not None]\n",
    "    labels = [i for i in labels if i!='nan']\n",
    "    print (labels)\n",
    "    \n",
    "    for label in labels :\n",
    "        saveHist(OutFolder+label+\".csv\",\"NDVI\",OutFolder+label+\"_hist.jpg\") \n",
    "         \n",
    "## function 9 takes the output of PlotToSat and adds the NDVI of each month\n",
    "def addNDVIpermonth(inCsvFile,Col,PlotsIdCol,outCsvFile):\n",
    "    df = pd.read_csv(inCsvFile,low_memory=False) \n",
    "    df[ '0_NDVI'] = (df[ '0_B8']-df[ '0_B4'])/(df[ '0_B8']+df[ '0_B4'])   # NDVI = (NIR-B8 - RED-B4) / (NIR-B8 + RED-B4) \n",
    "    df[ '1_NDVI'] = (df[ '1_B8']-df[ '1_B4'])/(df[ '1_B8']+df[ '1_B4'])   # NDVI = (NIR-B8 - RED-B4) / (NIR-B8 + RED-B4) \n",
    "    df[ '2_NDVI'] = (df[ '2_B8']-df[ '2_B4'])/(df[ '2_B8']+df[ '2_B4'])   # NDVI = (NIR-B8 - RED-B4) / (NIR-B8 + RED-B4) \n",
    "    df[ '3_NDVI'] = (df[ '3_B8']-df[ '3_B4'])/(df[ '3_B8']+df[ '3_B4'])   # NDVI = (NIR-B8 - RED-B4) / (NIR-B8 + RED-B4) \n",
    "    df[ '4_NDVI'] = (df[ '4_B8']-df[ '4_B4'])/(df[ '4_B8']+df[ '4_B4'])   # NDVI = (NIR-B8 - RED-B4) / (NIR-B8 + RED-B4) \n",
    "    df[ '5_NDVI'] = (df[ '5_B8']-df[ '5_B4'])/(df[ '5_B8']+df[ '5_B4'])   # NDVI = (NIR-B8 - RED-B4) / (NIR-B8 + RED-B4) \n",
    "    df[ '6_NDVI'] = (df[ '6_B8']-df[ '6_B4'])/(df[ '6_B8']+df[ '6_B4'])   # NDVI = (NIR-B8 - RED-B4) / (NIR-B8 + RED-B4) \n",
    "    df[ '7_NDVI'] = (df[ '7_B8']-df[ '7_B4'])/(df[ '7_B8']+df[ '7_B4'])   # NDVI = (NIR-B8 - RED-B4) / (NIR-B8 + RED-B4) \n",
    "    df[ '8_NDVI'] = (df[ '8_B8']-df[ '8_B4'])/(df[ '8_B8']+df[ '8_B4'])   # NDVI = (NIR-B8 - RED-B4) / (NIR-B8 + RED-B4) \n",
    "    df[ '9_NDVI'] = (df[ '9_B8']-df[ '9_B4'])/(df[ '9_B8']+df[ '9_B4'])   # NDVI = (NIR-B8 - RED-B4) / (NIR-B8 + RED-B4) \n",
    "    df['10_NDVI'] = (df['10_B8']-df['10_B4'])/(df['10_B8']+df['10_B4'])   # NDVI = (NIR-B8 - RED-B4) / (NIR-B8 + RED-B4) \n",
    "    df['11_NDVI'] = (df['11_B8']-df['11_B4'])/(df['11_B8']+df['11_B4'])   # NDVI = (NIR-B8 - RED-B4) / (NIR-B8 + RED-B4) \n",
    "    df = df[[Col, PlotsIdCol, \"0_NDVI\", \"1_NDVI\",\"2_NDVI\",\"3_NDVI\", \"4_NDVI\", \"5_NDVI\", \"6_NDVI\", \"7_NDVI\", \"8_NDVI\", \"9_NDVI\", \"10_NDVI\", \"11_NDVI\"]]\n",
    "    df.to_csv(outCsvFile)\n",
    "    print (\"Csv file with NDVs export in \", outCsvFile)\n",
    "\n",
    "\n",
    "## function 9.1 takes as input the outputs of function 9 or any other csv files with the same structure and average them correspondingly. \n",
    "## e.g., an example is to take the monthly NDVI for 2018, 2019 and 2020 and it will return the average monthly NDVI of the three given years\n",
    "## it further removes empty lines\n",
    "## @param [in] thress the threshold for empty lines, e.g., if thres = 8 if 8 or more values are empty within a row then the row is removed\n",
    "def aveCsvFiles(listOfFiles, col, PlotsIdCol, outfile, thres):\n",
    "    if (listOfFiles == []):\n",
    "        raise Exception(\"list is empty\")\n",
    "    df1 =  pd.read_csv(listOfFiles[0],low_memory=False) \n",
    "    df1.sort_values(by=PlotsIdCol,ascending=True)\n",
    "\n",
    "    if(len(listOfFiles)==1):\n",
    "        df1.to_csv(outfile)\n",
    "        print(\"   *** EXIT SUCCESS   ***\")\n",
    "        return\n",
    "       \n",
    "    \n",
    "    df2 =  pd.read_csv(listOfFiles[1],low_memory=False) \n",
    "    df2.sort_values(by=PlotsIdCol,ascending=True)\n",
    "    count = 1 \n",
    "    for col_name in df1.columns: \n",
    "        if(count==1 or count==2):\n",
    "            count = count+1\n",
    "            continue\n",
    "        df1[col_name] = pd.to_numeric(df1[col_name], errors='coerce')\n",
    "        df2[col_name] = pd.to_numeric(df2[col_name], errors='coerce')\n",
    "        if(col_name==col or col_name==PlotsIdCol):\n",
    "           continue\n",
    "        for idx, value in enumerate(df2[col_name]):\n",
    "            val1 = df1.at[idx, col_name]\n",
    "            val2 = df2.at[idx, col_name] \n",
    "            if pd.isna(val2) or val2 is None:\n",
    "                val2 = val1\n",
    "            if pd.isna(val1) or val1 is None:\n",
    "                val1 = val2\n",
    "            df1.at[idx, col_name] = (val1+val2)/2\n",
    "\n",
    "        \n",
    "    count = 0\n",
    "    for l in listOfFiles :\n",
    "        if(count==1 or count==2):\n",
    "            count = count+1\n",
    "            continue\n",
    "        \n",
    "        df2 = pd.read_csv(l)\n",
    "        df2[col] = pd.to_numeric(df2[col], errors='coerce')\n",
    "        for idx, value in enumerate(df2[col_name]):\n",
    "            val1 = df1.at[idx, col_name]\n",
    "            val2 = df2.at[idx, col_name] \n",
    "            if pd.isna(val2) or val2 is None:\n",
    "                val2 = val1\n",
    "            if pd.isna(val1) or val1 is None:\n",
    "                val1 = val2\n",
    "            df1.at[idx, col_name] = (val1+val2)/2\n",
    "   \n",
    "\n",
    "\n",
    "    for index, row in df1.iterrows():\n",
    "        count = 0\n",
    "        nullVals = 0 \n",
    "        for column in df1:\n",
    "            if(count==1 or count==2):\n",
    "                count = count+1\n",
    "                continue\n",
    "            val1 = df1.at[index, column]\n",
    "            if pd.isna(val1) or val1 is None:\n",
    "                nullVals=nullVals+1\n",
    "        if(nullVals>=thres):\n",
    "           df1=df1.drop(index)\n",
    "\n",
    "    df1.to_csv(outfile)\n",
    "    print (\"***   EXIT SUCCESS   ***\")\n",
    "    \n",
    "    \n",
    "## function 10 takes as input the output of function 9, for each unique label in Col it gets the mean for each monthly NDVI \n",
    "def getMeanNDVIsPerMonthForClass(inCsvFile,Col,PlotsIdCol, outCsvFile):\n",
    "    csvDF = pd.read_csv(inCsvFile,low_memory=False)\n",
    "    # '0_NDVI',  '1_NDVI', '2_NDVI', '3_NDVI', '4_NDVI', '5_NDVI', '6_NDVI', '7_NDVI', '8_NDVI',  '9_NDVI', '10_NDVI', '11_NDVI', \n",
    "    labels = list(csvDF.columns)\n",
    "    if (Col not in labels):\n",
    "        raise Exception(\"ERROR: \", Col, \" not included in \", inCsvFile)\n",
    "    newLabels = [Col] \n",
    "    l = 0\n",
    "    while (l<len(labels)):\n",
    "        if ((labels[l][0].isdigit() and labels[l][1]==\"_\") or \n",
    "            (labels[l][0].isdigit() and labels[l][1].isdigit() and labels[l][2]==\"_\")):\n",
    "            newLabels.append(labels[l])\n",
    "        l=l+1\n",
    "    \n",
    "    newLabelsS2 = [PlotsIdCol, Col, '0_NDVI',  '1_NDVI', '2_NDVI', '3_NDVI', '4_NDVI', '5_NDVI', '6_NDVI', '7_NDVI', '8_NDVI',  '9_NDVI', '10_NDVI', '11_NDVI']\n",
    "    print(newLabelsS2)    \n",
    "    csvDFS2 = csvDF.loc[:,newLabelsS2]\n",
    "    csvDFS2.to_csv(outCsvFile+\"_allNDVIdata.csv\")\n",
    "    csvDFS2=csvDFS2.groupby(Col).mean()\n",
    "    csvDFS2.to_csv(outCsvFile)\n",
    "    print(\"Mean monthy NDVIs of class \", Col, \" stored in \", outCsvFile)\n",
    "\n",
    "\n",
    "    \n",
    "## function 10.5 takes as input the outputs of function 10 and finds the best month to distingished clasess of interest\n",
    "# inCsvFile+_allNDvidata.csv was exported in function 10.5 and used here\n",
    "def getMonthForBetterDistingishingClasses(inCsvFile,Col):\n",
    "    dfMean = pd.read_csv(inCsvFile, low_memory=False)\n",
    "    dfMean = dfMean.drop(dfMean[dfMean[Col] == 'mixed'].index)\n",
    "    dfMean['count'] = [0,0,0,0]\n",
    "    sqrDifs = np.zeros(12)\n",
    "    dfAll  = pd.read_csv(inCsvFile+\"_allNDVIdata.csv\", low_memory=False)\n",
    "    dfAll.set_index(Col, inplace=True)\n",
    "    #dfAll = dfAll.grouby(Col)\n",
    "    dfAll = dfAll.drop(dfMean[dfMean[Col] == 'mixed'].index)\n",
    "    print(dfMean)\n",
    "    print(\"sqrDifs = \",sqrDifs)\n",
    "    \n",
    "    \n",
    "        \n",
    "## function 11 takes as input the output of function 10 and creates a multiline graph for the mean NDVIs of each class\n",
    "def createGraphOfNDVIs(inCsvFile, Col, outImg):\n",
    "    df = pd.read_csv(inCsvFile, low_memory=False)\n",
    "    df.set_index(Col, inplace=True)\n",
    "    plt.figure(figsize=(14,6),  dpi=300)\n",
    "    df.T.plot(marker='o', linestyle='-')\n",
    "    plt.title(\"NDVI during 2019 of different forest types\")\n",
    "    plt.xlabel(\"Months\")\n",
    "    plt.ylabel(\"NDVI Values\")\n",
    "    plt.legend(title=\"Forest Types\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(outImg)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    print(\"Image saved in \", outImg)\n",
    "    \n",
    "    \n",
    "## function 12 takes as input the output of function 9 and creates a multiline graph for the mean and std NDVIs of each class \n",
    "# # NOT WORKING\n",
    "def creatGraphOfNDVIsWithStd(inCsvFile,Col,outImg):\n",
    "    df = pd.read_csv(inCsvFile, low_memory=False)\n",
    "\n",
    "    # Set the 'Col' column as the index\n",
    "    df.set_index(Col, inplace=True)\n",
    "    \n",
    "\n",
    "    # Extract mean and std values\n",
    "    means = df.groupby(Col).mean()\n",
    "    stds = df.groupby(Col).std().fillna(df.groupby(Col).last())\n",
    "    \n",
    "    print (means)\n",
    "    print (stds)\n",
    "    print (\"HELLO WORLDS\")\n",
    "\n",
    "    # Plot the multiline graph with mean and std\n",
    "    plt.figure(figsize=(14, 6), dpi=300)\n",
    "    for label, mean_values, std_values in zip(means.index, means.values.T, stds.values.T):\n",
    "        plt.errorbar(x=means.columns, y=mean_values, yerr=std_values, marker='o', linestyle='-', label=label, alpha=0.7)\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.title(\"Mean NDVI during 2019 of different forest types with Standard Deviation\")\n",
    "    plt.xlabel(\"Months\")\n",
    "    plt.ylabel(\"NDVI Values\")\n",
    "    plt.legend(title=\"Forest Types\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Save the plot to the specified output image file\n",
    "    plt.savefig(outImg)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    # Clear the plot\n",
    "    plt.clf()\n",
    "\n",
    "    print(\"Image saved in \", outImg)\n",
    "\n",
    "\n",
    "## function 13 takes as input a txt file and returns stats about execution time - file manually created by copying GEE output in Tasks\n",
    "# locations of files hardcoded because run only once\n",
    "def getExecutionTimeStatsforFile(inFile):\n",
    "  \n",
    "    file = open(inFile, 'r')\n",
    "    lines = file.readlines()\n",
    "    count = 0\n",
    "    allmins = []\n",
    "    S2_stdD_mins = []\n",
    "    S2_mean_mins = []\n",
    "    S1_stdD_mins = []\n",
    "    S1_mean_mins = []\n",
    "    invalidValues=0\n",
    "    for line in lines: \n",
    "        if count%2 != 0 : \n",
    "            line  = line.replace('m', '')\n",
    "            line  = line.replace('\\n', '')\n",
    "            try: \n",
    "                mins = int(line)\n",
    "                allmins = allmins + [mins]\n",
    "            except:\n",
    "                print (\"WARNING: one invalid value\")\n",
    "                invalidValues = invalidValues+1\n",
    "                allmins = allmins + [-1]\n",
    "        count = count + 1\n",
    "\n",
    "    allmins=np.array(allmins)\n",
    "    for x in range (0,len(allmins)):\n",
    "        if( x%4 == 0):\n",
    "            S2_stdD_mins = S2_stdD_mins + [allmins[x]]\n",
    "        if (x%4 == 1):\n",
    "            S2_mean_mins = S2_mean_mins + [allmins[x]]\n",
    "        if (x%4 == 2):\n",
    "            S1_stdD_mins = S1_stdD_mins + [allmins[x]]\n",
    "        if (x%4 == 3):\n",
    "            S1_mean_mins = S1_mean_mins + [allmins[x]]\n",
    "            \n",
    "    print( \"NAME, MEAN, STD, LEN, INVALID\")\n",
    "    \n",
    "    S2_stdD_minsInv = len(S2_stdD_mins)\n",
    "    S2_stdD_mins = [ v for v in S2_stdD_mins if v  >= 0 ]\n",
    "    S2_stdD_mins = np.array(S2_stdD_mins)\n",
    "    S2_stdD_minsInv = S2_stdD_minsInv-len(S2_stdD_mins)\n",
    "    print (\"S2_stdD_mins\", round(S2_stdD_mins.mean(),3), round(S2_stdD_mins.std(),3),len(S2_stdD_mins),S2_stdD_minsInv)\n",
    "    \n",
    "    S2_mean_minsInv = len(S2_mean_mins)\n",
    "    S2_mean_mins = [ v for v in S2_mean_mins if v  >= 0]\n",
    "    S2_mean_mins = np.array(S2_mean_mins)\n",
    "    S2_mean_minsInv = S2_mean_minsInv-len(S2_mean_mins)\n",
    "    print (\"S2_mean_mins\", round(S2_mean_mins.mean(),3), round(S2_mean_mins.std(),3),len(S2_mean_mins),S2_mean_minsInv)\n",
    "    \n",
    "    S1_stdD_minsInv = len(S1_stdD_mins)\n",
    "    S1_stdD_mins = [ v for v in S1_stdD_mins if v  >= 0]\n",
    "    S1_stdD_mins = np.array(S1_stdD_mins)\n",
    "    S1_stdD_minsInv = S1_stdD_minsInv-len(S1_stdD_mins)\n",
    "    print (\"S1_stdD_mins\", round(S1_stdD_mins.mean(),3), round(S1_stdD_mins.std(),3),len(S1_stdD_mins),S1_stdD_minsInv)\n",
    "\n",
    "    S1_mean_minsInv = len(S1_mean_mins)\n",
    "    S1_mean_mins = [ v for v in S1_mean_mins if v  >= 0]\n",
    "    S1_mean_mins = np.array(S1_mean_mins)\n",
    "    S1_mean_minsInv = S1_mean_minsInv-len(S1_mean_mins)\n",
    "    print (\"S1_mean_mins\", round(S1_mean_mins.mean(),3), round(S1_mean_mins.std(),3),len(S1_mean_mins),S1_mean_minsInv)\n",
    "\n",
    "    print (allmins.mean(),allmins.std(),len(allmins),invalidValues)\n",
    "    file.close()\n",
    "    \n",
    "\n",
    "def getExecutionTimeStats():\n",
    "    radius25  = \"/home/milto/Documents/fieldData/statsNImgs/Radius25.txt\" \n",
    "    radius50  = \"/home/milto/Documents/fieldData/statsNImgs/Radius50.txt\" \n",
    "    radius100 = \"/home/milto/Documents/fieldData/statsNImgs/Radius100.txt\" \n",
    "    print(\"******************\\nRADIUS 25\")\n",
    "    getExecutionTimeStatsforFile(radius25)\n",
    "    print(\"******************\\nRADIUS 50\")\n",
    "    getExecutionTimeStatsforFile(radius50)\n",
    "    print(\"******************\\nRADIUS 100\")\n",
    "    getExecutionTimeStatsforFile(radius100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
